{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtM8OK0sJiv7"
   },
   "source": [
    "# Generating Questions with the same/Similar Meaning and Context "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYB7UeQJNuB2"
   },
   "outputs": [],
   "source": [
    "!wget -q http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "bX7bmPCkNzPb",
    "outputId": "4c132d56-f0c3-412f-bee0-5cba02e5adfe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  ...                                          question2 is_duplicate\n",
       "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
       "1   1     3  ...  What would happen if the Indian government sto...            0\n",
       "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
       "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
       "4   4     9  ...            Which fish would survive in salt water?            0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('/content/quora_duplicate_questions.tsv',delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdWP3ZyTSOA6",
    "outputId": "ebdf133e-719a-42cb-f2d9-7129f1107a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some of the data out so you can have a look at it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuFhgjPMOVYk",
    "outputId": "b5de5246-21cc-46f1-c3e6-dce8aa1443ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: What is the step by step guide to invest in share market in india?\n",
      "\u001b[1mQ2\u001b[0m: What is the step by step guide to invest in share market?\n",
      "\n",
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
      "\u001b[1mQ2\u001b[0m: What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n",
      "\n",
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: How can I increase the speed of my internet connection while using a VPN?\n",
      "\u001b[1mQ2\u001b[0m: How can Internet speed be increased by hacking through DNS?\n",
      "\n",
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: Why am I mentally very lonely? How can I solve it?\n",
      "\u001b[1mQ2\u001b[0m: Find the remainder when [math]23^{24}[/math] is divided by 24,23?\n",
      "\n",
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
      "\u001b[1mQ2\u001b[0m: Which fish would survive in salt water?\n",
      "\n",
      "                                         \u001b[1mDuplicate\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "\u001b[1mQ2\u001b[0m: I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "\n",
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: Should I buy tiago?\n",
      "\u001b[1mQ2\u001b[0m: What keeps childern active and far from phone and video games?\n",
      "\n",
      "                                         \u001b[1mDuplicate\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: How can I be a good geologist?\n",
      "\u001b[1mQ2\u001b[0m: What should I do to be a great geologist?\n",
      "\n",
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: When do you use シ instead of し?\n",
      "\u001b[1mQ2\u001b[0m: When do you use \"&\" instead of \"and\"?\n",
      "\n",
      "                                         \u001b[1mDifferent\u001b[0m                                          \n",
      "\u001b[1mQ1\u001b[0m: Motorola (company): Can I hack my Charter Motorolla DCX3400?\n",
      "\u001b[1mQ2\u001b[0m: How do I hack Motorola DCX3400 for free internet?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    i = df.iloc[i]\n",
    "    print((\"\\033[1m\"+\"Duplicate\"+\"\\033[0m\").center(100) if i.is_duplicate==1 \\\n",
    "          else (\"\\033[1m\"+\"Different\"+\"\\033[0m\").center(100))\n",
    "    print(\"\\033[1m\"+\"Q1\"+\"\\033[0m\"+\":\", i.question1)\n",
    "    print(\"\\033[1m\"+\"Q2\"+\"\\033[0m\"+\":\", i.question2+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0TfB0UrXqnx",
    "outputId": "bef13572-1e35-4cdf-8768-dae81447c6b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149263"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.is_duplicate==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need columns other than question1 and question2, so get rid of the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "BOjIR-1pXx7b",
    "outputId": "fe5d97a9-ebab-4365-b403-038d32ae86bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>How can you make physics easy to learn?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>What was your first sexual experience?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What does manipulation mean?</td>\n",
       "      <td>What does manipulation means?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Why are so many Quora users posting questions ...</td>\n",
       "      <td>Why do people ask Quora questions which can be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>Why are rockets and boosters painted white?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How should I prepare for CA final law?</td>\n",
       "      <td>How one should know that he/she completely pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1                                          question2\n",
       "0  Astrology: I am a Capricorn Sun Cap moon and c...  I'm a triple Capricorn (Sun, Moon and ascendan...\n",
       "1                     How can I be a good geologist?          What should I do to be a great geologist?\n",
       "2        How do I read and find my YouTube comments?             How can I see all my Youtube comments?\n",
       "3               What can make Physics easy to learn?            How can you make physics easy to learn?\n",
       "4        What was your first sexual experience like?             What was your first sexual experience?\n",
       "5  What would a Trump presidency mean for current...  How will a Trump presidency affect the student...\n",
       "6                       What does manipulation mean?                      What does manipulation means?\n",
       "7  Why are so many Quora users posting questions ...  Why do people ask Quora questions which can be...\n",
       "8                         Why do rockets look white?        Why are rockets and boosters painted white?\n",
       "9             How should I prepare for CA final law?  How one should know that he/she completely pre..."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicate = df[df.is_duplicate==1].reset_index() \n",
    "                \n",
    "df_duplicate = df_duplicate.drop([\"index\",\"id\",\"qid1\",\"qid2\",\"is_duplicate\"],axis=1)\n",
    "df_duplicate.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMGSoTyCO4_8",
    "outputId": "eaa9be95-3c96-4be0-cd56-16a02c1d8978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-24 09:42:58.832396: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy --upgrade --quiet\n",
    "!python -m spacy download en --quiet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgQXaehPSYkO",
    "outputId": "2abe7191-9973-455d-80aa-2be545d2fb6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119410, 29853)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df,valid_df = train_test_split(df_duplicate,test_size=0.2)\n",
    "len(train_df),len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "a8wv1bb2cTUa",
    "outputId": "ace5cb80-34be-4ac0-d36f-aa8642e9f3dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90533</th>\n",
       "      <td>Which programming language is the best to lear...</td>\n",
       "      <td>What language should I learn first?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103293</th>\n",
       "      <td>Why do you(or not) support Israel?</td>\n",
       "      <td>Do you support the existence of Israel? Why?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62720</th>\n",
       "      <td>What are Common Preparation Mistakes of IIT JE...</td>\n",
       "      <td>What are common mistakes students do in IIT JE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28357</th>\n",
       "      <td>Why are humans born?</td>\n",
       "      <td>Why were humans born?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27123</th>\n",
       "      <td>How is Donald Trump winning?</td>\n",
       "      <td>Why did American people elect Donald Trump as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1                                          question2\n",
       "90533   Which programming language is the best to lear...                What language should I learn first?\n",
       "103293                 Why do you(or not) support Israel?       Do you support the existence of Israel? Why?\n",
       "62720   What are Common Preparation Mistakes of IIT JE...  What are common mistakes students do in IIT JE...\n",
       "28357                                Why are humans born?                              Why were humans born?\n",
       "27123                        How is Donald Trump winning?  Why did American people elect Donald Trump as ..."
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "QetNussNceEC",
    "outputId": "f015cb51-b4a5-4b6b-9652-d358570fa88b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34152</th>\n",
       "      <td>Is joining coaching center necessary to clear ...</td>\n",
       "      <td>Is coaching necessary to crack JEE Advanced?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30878</th>\n",
       "      <td>What are common symptoms of bipolar disorder?</td>\n",
       "      <td>What are the symptoms of bipolar disorder?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67545</th>\n",
       "      <td>What are some songs that everyone must listen to?</td>\n",
       "      <td>What are some good songs to listen to?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90110</th>\n",
       "      <td>Who would win in a war between Russia and the US?</td>\n",
       "      <td>If America went to war with Russia who would w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101646</th>\n",
       "      <td>What are two ways the U.S. Constitution can be...</td>\n",
       "      <td>How can an amendment to the U.S. Constitution ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1                                          question2\n",
       "34152   Is joining coaching center necessary to clear ...       Is coaching necessary to crack JEE Advanced?\n",
       "30878       What are common symptoms of bipolar disorder?         What are the symptoms of bipolar disorder?\n",
       "67545   What are some songs that everyone must listen to?             What are some good songs to listen to?\n",
       "90110   Who would win in a war between Russia and the US?  If America went to war with Russia who would w...\n",
       "101646  What are two ways the U.S. Constitution can be...  How can an amendment to the U.S. Constitution ..."
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6D7_HQPUSv_",
    "outputId": "175a014e-2dce-484e-bfec-0ba1e4e77e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.to_csv('train.csv',index=False),valid_df.to_csv('valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVToA-YHbMO0"
   },
   "outputs": [],
   "source": [
    "spacy = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "in8BZDX0bE52"
   },
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TePToO1lWt6m"
   },
   "outputs": [],
   "source": [
    "Q1 = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "Q2 = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gp051_mXayed"
   },
   "outputs": [],
   "source": [
    "fields = [('q1', Q1),('q2', Q2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Datasets needed for creating the DataLoaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FF8cLMPRpvq"
   },
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "\n",
    "train_data, valid_data = data.TabularDataset.splits(\n",
    "                                        path = '/content',\n",
    "                                        train = 'train.csv',\n",
    "                                        validation = 'valid.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmvbEq4ESGBW",
    "outputId": "d3c8f1d5-76cf-4b46-a0c5-ce4a0d6e8729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119410, 29853)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIghRURXbwG-",
    "outputId": "de3b459c-047b-4b61-8d52-3fc7c8e50900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 119410\n",
      "Number of validation examples: 29853\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look into Dataset structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xETJI9sdb91v",
    "outputId": "1271f820-9100-4a18-cc24-fadd63af85ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q1': ['which', 'programming', 'language', 'is', 'the', 'best', 'to', 'learn', 'first', '?'], 'q2': ['what', 'language', 'should', 'i', 'learn', 'first', '?']} \n",
      "\n",
      "{'q1': ['why', 'do', 'you(or', 'not', ')', 'support', 'israel', '?'], 'q2': ['do', 'you', 'support', 'the', 'existence', 'of', 'israel', '?', 'why', '?']} \n",
      "\n",
      "{'q1': ['what', 'are', 'common', 'preparation', 'mistakes', 'of', 'iit', 'jee', 'advanced', '?'], 'q2': ['what', 'are', 'common', 'mistakes', 'students', 'do', 'in', 'iit', 'jee', 'preparation', '?']} \n",
      "\n",
      "{'q1': ['why', 'are', 'humans', 'born', '?'], 'q2': ['why', 'were', 'humans', 'born', '?']} \n",
      "\n",
      "{'q1': ['how', 'is', 'donald', 'trump', 'winning', '?'], 'q2': ['why', 'did', 'american', 'people', 'elect', 'donald', 'trump', 'as', 'their', 'president', '?']} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  print(vars(train_data.examples[i]),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5OSPWGtcFFN"
   },
   "outputs": [],
   "source": [
    "Q1.build_vocab(train_data, min_freq = 2)\n",
    "Q2.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DY6tH_hQc_9p",
    "outputId": "ae542af4-91a9-45cf-e14f-0a7929dd5c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 15367\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (de) vocabulary: {len(Q1.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXnVmS_IdFVg"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the DataIterators needed for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkYw3pRddPlF"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort=False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size and Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IK2kzeXIgmiX"
   },
   "outputs": [],
   "source": [
    "example = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5JlTpKph47R",
    "outputId": "555fcc2c-a537-4468-acc6-2bf41d696bbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 128]), torch.Size([26, 128]))"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.q1.shape,example.q2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_D4iULzdWbX"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6J_OTXcWiI57"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(Q1.vocab)\n",
    "EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "enc_test = Encoder(INPUT_DIM,EMB_DIM,HID_DIM,N_LAYERS,DROPOUT).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity and Shape check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VERR3FjIjbNw",
    "outputId": "1e06dc1f-d86e-4b98-dab1-0978fe7ea206"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 128])"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9xLAUvnitwB",
    "outputId": "5eee80d9-b748-43f0-acf0-5b63fb3a3619"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128, 512]), torch.Size([2, 128, 512]))"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden,cell = enc_test(example.q1)\n",
    "hidden.shape,cell.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJ8Qr-3BdaSz"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim,output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzZXjXcWi4Gd"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = len(Q2.vocab)\n",
    "EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "dec_test = Decoder(INPUT_DIM,EMB_DIM,HID_DIM,N_LAYERS,DROPOUT).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq module integrating Encoder and Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeMRDyGJdwFO"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the model and pop it onto the GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9Oas5qMd4Zx"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(Q1.vocab)\n",
    "OUTPUT_DIM = len(Q2.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PD0fL14leG4y",
    "outputId": "42fc6598-c187-4ce1-e067-205367a1ff6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 23,107,591 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose Optimizer and Loss fuction Criteria  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joGMNkbzelXn"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWOiUjAPepY3"
   },
   "outputs": [],
   "source": [
    "Q2_PAD_IDX =Q2.vocab.stoi[Q2.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = Q2_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzaM2Zs3exzH"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        Q1 = batch.q1\n",
    "        Q2= batch.q2\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(Q1, Q2)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        Q2 = Q2[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output,Q2)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlhKcXSGf76X"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            Q1 = batch.q1\n",
    "            Q2= batch.q2\n",
    "\n",
    "            output = model(Q1,Q2, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            Q2 = Q2[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, Q2)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "375t5vUSgIU8"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4oD4EnigMRU",
    "outputId": "330672da-72c5-4fef-ff1e-ee475e26f86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 10m 15s\n",
      "\tTrain Loss: 4.908 | Train PPL: 135.314\n",
      "\t Val. Loss: 4.743 |  Val. PPL: 114.722\n",
      "Epoch: 02 | Time: 10m 15s\n",
      "\tTrain Loss: 4.027 | Train PPL:  56.077\n",
      "\t Val. Loss: 4.325 |  Val. PPL:  75.596\n",
      "Epoch: 03 | Time: 10m 16s\n",
      "\tTrain Loss: 3.610 | Train PPL:  36.955\n",
      "\t Val. Loss: 4.137 |  Val. PPL:  62.593\n",
      "Epoch: 04 | Time: 10m 19s\n",
      "\tTrain Loss: 3.350 | Train PPL:  28.500\n",
      "\t Val. Loss: 4.024 |  Val. PPL:  55.925\n",
      "Epoch: 05 | Time: 10m 19s\n",
      "\tTrain Loss: 3.167 | Train PPL:  23.730\n",
      "\t Val. Loss: 3.947 |  Val. PPL:  51.801\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run for 5 more Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FbRkasBpjMJ",
    "outputId": "47ab0fd4-9f4d-4a1e-821b-01161539f458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 10m 18s\n",
      "\tTrain Loss: 2.995 | Train PPL:  19.988\n",
      "\t Val. Loss: 3.893 |  Val. PPL:  49.051\n",
      "Epoch: 02 | Time: 10m 20s\n",
      "\tTrain Loss: 2.873 | Train PPL:  17.687\n",
      "\t Val. Loss: 3.815 |  Val. PPL:  45.358\n",
      "Epoch: 03 | Time: 10m 23s\n",
      "\tTrain Loss: 2.756 | Train PPL:  15.741\n",
      "\t Val. Loss: 3.835 |  Val. PPL:  46.297\n",
      "Epoch: 04 | Time: 10m 24s\n",
      "\tTrain Loss: 2.677 | Train PPL:  14.548\n",
      "\t Val. Loss: 3.768 |  Val. PPL:  43.304\n",
      "Epoch: 05 | Time: 10m 20s\n",
      "\tTrain Loss: 2.577 | Train PPL:  13.156\n",
      "\t Val. Loss: 3.757 |  Val. PPL:  42.829\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Quora_similiar_questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
