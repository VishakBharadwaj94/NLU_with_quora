{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBUiaGFqg1fG"
   },
   "source": [
    "# Sentiment Classification of Stanford Sentiment TreeBank (SST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjO5B_FPhF4a"
   },
   "source": [
    "## Data Handling and cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VCAOVCwQsId0"
   },
   "outputs": [],
   "source": [
    "! wget -q http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mwr12tWu2exn"
   },
   "outputs": [],
   "source": [
    "!unzip -q /content/stanfordSentimentTreebank.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9IclS7h8cNU-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9ajW0C6qcmC-"
   },
   "outputs": [],
   "source": [
    "sst_dir = 'stanfordSentimentTreebank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "td30xzFpcooE",
    "outputId": "47b909f7-7cfc-4b76-f131-5ab514a7d5b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_ids</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.42708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_ids  sentiment_values\n",
       "0           0           0.50000\n",
       "1           1           0.50000\n",
       "2           2           0.44444\n",
       "3           3           0.50000\n",
       "4           4           0.42708"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels = pd.read_csv(\n",
    "    os.path.join(sst_dir, \"sentiment_labels.txt\"),\n",
    "     names=['phrase_ids', 'sentiment_values'], \n",
    "     sep=\"|\",\n",
    "      header=0)\n",
    "\n",
    "sentiment_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0--BTAzKEg2T"
   },
   "outputs": [],
   "source": [
    "def discretize_label(label):\n",
    "    if label <= 0.2: \n",
    "      return 0\n",
    "    elif label <= 0.4: \n",
    "      return 1\n",
    "    elif label <= 0.6: \n",
    "      return 2\n",
    "    elif label <= 0.8: \n",
    "      return 3\n",
    "\n",
    "    return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "VyzRffg8EaVE",
    "outputId": "b3c763a7-1700-4976-d959-cea8dba6eddc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_ids</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_ids  sentiment_values\n",
       "0           0                 2\n",
       "1           1                 2\n",
       "2           2                 2\n",
       "3           3                 2\n",
       "4           4                 2"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels['sentiment_values'] = sentiment_labels['sentiment_values'].apply(discretize_label)\n",
    "sentiment_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "0O_HDEfKEqTR",
    "outputId": "ea6f9362-2eca-498e-9e87-26241f82f363"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_index                                           sentence\n",
       "0               1  The Rock is destined to be the 21st Century 's...\n",
       "1               2  The gorgeously elaborate continuation of `` Th...\n",
       "2               3                     Effective but too-tepid biopic\n",
       "3               4  If you sometimes like to go to the movies to h...\n",
       "4               5  Emerges as something rare , an issue movie tha..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_ids = pd.read_csv(\n",
    "    os.path.join(sst_dir, \"datasetSentences.txt\"),\n",
    "     sep=\"\\t\")\n",
    "\n",
    "sentence_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "vYNv1nkLvrvv",
    "outputId": "003a19d6-979e-4bd8-bd2a-e6d471e452f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>! '</td>\n",
       "      <td>22935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>! ''</td>\n",
       "      <td>18235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>! Alas</td>\n",
       "      <td>179257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>! Brilliant</td>\n",
       "      <td>22936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        phrase  phrase_ids\n",
       "0            !           0\n",
       "1          ! '       22935\n",
       "2         ! ''       18235\n",
       "3       ! Alas      179257\n",
       "4  ! Brilliant       22936"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv(\n",
    "    os.path.join(sst_dir, \"dictionary.txt\"),\n",
    "     sep=\"|\", \n",
    "     names=['phrase', 'phrase_ids'])\n",
    "\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "uG8w01caYPA7",
    "outputId": "420291bd-e1d8-4d11-bc56-3aa48f54197b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>splitset_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_index  splitset_label\n",
       "0               1               1\n",
       "1               2               1\n",
       "2               3               2\n",
       "3               4               2\n",
       "4               5               2"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split = pd.read_csv(\n",
    "    os.path.join(sst_dir, \"datasetSplit.txt\"))\n",
    "\n",
    "train_test_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "d580T5iieY3f"
   },
   "outputs": [],
   "source": [
    "sentence_phrase_merge = pd.merge(sentence_ids, mapping, left_on='sentence', right_on='phrase')\n",
    "sentence_phrase_split = pd.merge(sentence_phrase_merge, train_test_split, on='sentence_index')\n",
    "dataset = pd.merge(sentence_phrase_split, sentiment_labels, on='phrase_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "omslcMd6YDpE",
    "outputId": "b3775f68-08cf-47b8-a141-bb27825ec5b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase_ids</th>\n",
       "      <th>splitset_label</th>\n",
       "      <th>sentiment_values</th>\n",
       "      <th>phrase_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>226166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>226300</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>13995</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>14123</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>13999</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_index  ...                                     phrase_cleaned\n",
       "0               1  ...  The Rock is destined to be the 21st Century's ...\n",
       "1               2  ...  The gorgeously elaborate continuation of `` Th...\n",
       "2               3  ...                     Effective but too-tepid biopic\n",
       "3               4  ...  If you sometimes like to go to the movies to h...\n",
       "4               5  ...  Emerges as something rare , an issue movie tha...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['phrase_cleaned'] = dataset['sentence'].str.replace(\n",
    "    r\"\\s('s|'d|'re|'ll|'m|'ve|n't)\\b\",\n",
    "     lambda m: m.group(1))\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "EGkzqTh2fDEV",
    "outputId": "92b6bf8a-f3dd-42ff-c9ab-98e2a32e83e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>splitset_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11281</th>\n",
       "      <td>A real snooze .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11282</th>\n",
       "      <td>No surprises .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11283</th>\n",
       "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>Her fans walked out muttering words like `` ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11285</th>\n",
       "      <td>In this case zero .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11286 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  splitset_label\n",
       "0      The Rock is destined to be the 21st Century 's...      3               1\n",
       "1      The gorgeously elaborate continuation of `` Th...      4               1\n",
       "2                         Effective but too-tepid biopic      2               2\n",
       "3      If you sometimes like to go to the movies to h...      3               2\n",
       "4      Emerges as something rare , an issue movie tha...      4               2\n",
       "...                                                  ...    ...             ...\n",
       "11281                                    A real snooze .      0               1\n",
       "11282                                     No surprises .      1               1\n",
       "11283  We 've seen the hippie-turned-yuppie plot befo...      3               1\n",
       "11284  Her fans walked out muttering words like `` ho...      0               1\n",
       "11285                                In this case zero .      1               1\n",
       "\n",
       "[11286 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['sentence','sentiment_values','splitset_label']].rename(\n",
    "    columns={\"sentence\":\"text\",\"sentiment_values\":\"label\"})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "heU_GaaniaU9",
    "outputId": "62b62d93-b70c-4bce-f254-612ce8db1d48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>A real snooze .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>No surprises .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>Her fans walked out muttering words like `` ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>In this case zero .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     The Rock is destined to be the 21st Century 's...      3\n",
       "1     The gorgeously elaborate continuation of `` Th...      4\n",
       "2     Singer\\/composer Bryan Adams contributes a sle...      3\n",
       "3     You 'd think by now America would have had eno...      2\n",
       "4                  Yet the act is still charming here .      3\n",
       "...                                                 ...    ...\n",
       "8112                                    A real snooze .      0\n",
       "8113                                     No surprises .      1\n",
       "8114  We 've seen the hippie-turned-yuppie plot befo...      3\n",
       "8115  Her fans walked out muttering words like `` ho...      0\n",
       "8116                                In this case zero .      1\n",
       "\n",
       "[8117 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset[dataset.splitset_label==1].drop('splitset_label',axis='columns').reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3chDY33isc0",
    "outputId": "292034b9-573d-43f8-9d4f-ee32b3512b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2125, 1044)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = dataset[dataset.splitset_label==2].drop('splitset_label',axis='columns').reset_index(drop=True)\n",
    "test = dataset[dataset.splitset_label==3].drop('splitset_label',axis='columns').reset_index(drop=True)\n",
    "len(valid),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Uq2wxCG1jOYt"
   },
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "data_dict['train'] = train\n",
    "data_dict['dev'] = valid\n",
    "data_dict['test'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "JSWLK5mVki2D",
    "outputId": "4a91e88f-888b-4e90-9af2-9b8e70e1a2e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>A real snooze .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>No surprises .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>Her fans walked out muttering words like `` ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>In this case zero .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     The Rock is destined to be the 21st Century 's...      3\n",
       "1     The gorgeously elaborate continuation of `` Th...      4\n",
       "2     Singer\\/composer Bryan Adams contributes a sle...      3\n",
       "3     You 'd think by now America would have had eno...      2\n",
       "4                  Yet the act is still charming here .      3\n",
       "...                                                 ...    ...\n",
       "8112                                    A real snooze .      0\n",
       "8113                                     No surprises .      1\n",
       "8114  We 've seen the hippie-turned-yuppie plot befo...      3\n",
       "8115  Her fans walked out muttering words like `` ho...      0\n",
       "8116                                In this case zero .      1\n",
       "\n",
       "[8117 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qS20GnzhVJV"
   },
   "source": [
    "## Creating Data Pipelines for modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJ6o_79ISSVb"
   },
   "source": [
    "### Defining Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e63g08ijOrf7"
   },
   "source": [
    "Now we shall be defining LABEL as a LabelField, which is a subclass of Field that sets sequen tial to False (as it’s our numerical category class). TWEET is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qk8IP4SK1Lrp",
    "outputId": "12fe2a33-e5a4-4886-bfda-776544235ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6ea95fc830>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Library\n",
    "import random\n",
    "import torch, torchtext\n",
    "from torchtext import legacy\n",
    "from torchtext.legacy import data\n",
    "\n",
    "# Manual Seed\n",
    "SEED = 43\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "u6bKQax2Mf_U"
   },
   "outputs": [],
   "source": [
    "Text = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
    "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MMDBHQ9v6-nl"
   },
   "outputs": [],
   "source": [
    "fields=[('text',Text),('label',Label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjD-tsgf5CnJ",
    "outputId": "a01edc54-f648-43fe-e1b4-a9f4e47ede55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text', <torchtext.legacy.data.field.Field at 0x7f6ea82b7090>),\n",
       " ('label', <torchtext.legacy.data.field.LabelField at 0x7f6e62b47fd0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbtZ-Ph2P1xL"
   },
   "source": [
    "Armed with our declared fields, lets convert from pandas to list to torchtext. We could also use TabularDataset to apply that definition to the CSV directly but showing an alternative approach too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rjSiNIQRTM8o"
   },
   "outputs": [],
   "source": [
    "example_train=[data.Example.fromlist([data_dict['train'].text[i],data_dict['train'].label[i]],fields) for i in range (data_dict['train'].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nT-flpH-P1cd"
   },
   "outputs": [],
   "source": [
    "# Creating train dataset\n",
    "train = data.Dataset(example_train, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0YNvgFV5oIr",
    "outputId": "3514b6f3-0a5b-48e2-b1d6-5f5d36ae9d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Rock',\n",
       " 'is',\n",
       " 'destined',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " '21st',\n",
       " 'Century',\n",
       " \"'s\",\n",
       " 'new',\n",
       " '`',\n",
       " '`',\n",
       " 'Conan',\n",
       " \"''\",\n",
       " 'and',\n",
       " 'that',\n",
       " 'he',\n",
       " \"'s\",\n",
       " 'going']"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_train[0].text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BIpLIZRsTUwr"
   },
   "outputs": [],
   "source": [
    "example_dev=[data.Example.fromlist([data_dict['dev'].text[i],data_dict['dev'].label[i]],fields) for i in range (data_dict['dev'].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "DVPITjbYJq4n"
   },
   "outputs": [],
   "source": [
    "# Creating dev dataset\n",
    "dev = data.Dataset(example_dev, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykvsCGQMR6UD",
    "outputId": "bdd9c256-6dd6-4def-c02f-68ce4b4c60c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17517, 2125)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train),len(dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKdllP3FST4N"
   },
   "source": [
    "### Building Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuvWQ-SpSmSz"
   },
   "source": [
    "At this point we would have built a one-hot encoding of each word that is present in the dataset—a rather tedious process. Thankfully, torchtext will do this for us, and will also allow a max_size parameter to be passed in to limit the vocabulary to the most common words. This is normally done to prevent the construction of a huge, memory-hungry model. We don’t want our GPUs too overwhelmed, after all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukXt8VfvKKp5",
    "outputId": "100aee90-c2c1-4a3a-e12e-635603a5781a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:41, 5.33MB/s]                          \n",
      "100%|█████████▉| 399645/400000 [00:14<00:00, 27340.47it/s]"
     ]
    }
   ],
   "source": [
    "Text.build_vocab(train,vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "Label.build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvyEeEjXTGhX"
   },
   "source": [
    "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HsOUfeGYM6Uv",
    "outputId": "aac7b905-4ddb-41ea-9523-18e4613b7a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input vocab :  17491\n",
      "Size of label vocab :  5\n",
      "Top 10 words appreared repeatedly : [('.', 15888), (',', 13992), ('the', 11976), ('a', 9147), ('of', 8766), ('and', 8701), ('to', 5978), ('-', 5401), ('is', 5003), (\"'s\", 4796)]\n",
      "Labels :  defaultdict(None, {3: 0, 1: 1, 2: 2, 4: 3, 0: 4})\n"
     ]
    }
   ],
   "source": [
    "print('Size of input vocab : ', len(Text.vocab))\n",
    "print('Size of label vocab : ', len(Label.vocab))\n",
    "print('Top 10 words appreared repeatedly :', list(Text.vocab.freqs.most_common(10)))\n",
    "print('Labels : ', Label.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Zfo2QhGJUK4l"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "zK2ORoqdTNsM"
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = data.BucketIterator.splits((train, dev), batch_size = 32, \n",
    "                                                            sort_key = lambda x: len(x.text),\n",
    "                                                            sort_within_batch=True, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gg7gTFQO4fby"
   },
   "source": [
    "Save the vocabulary for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niE9Cc6-2bD_"
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "with open('tokenizer.pkl', 'wb') as tokens: \n",
    "    pickle.dump(Text.vocab.stoi, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AbsQwqkVyAy"
   },
   "source": [
    "## Defining Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4PED4HJWH4t"
   },
   "source": [
    "We use the Embedding and LSTM modules in PyTorch to build a simple model for classifying tweets.\n",
    "\n",
    "In this model we create three layers. \n",
    "1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n",
    "2. That’s then fed into a 2 stacked-LSTMs with 100 hidden features (again, we’re compressing down from the 300-dimensional input like we did with images). We are using 2 LSTMs for using the dropout.\n",
    "3. Finally, the output of the LSTM (the final hidden state after processing the incoming tweet) is pushed through a standard fully connected layer with three outputs to correspond to our three possible classes (negative, positive, or neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "43pVRccMT0bT"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout,pad_idx):\n",
    "        \n",
    "        super().__init__()          \n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim,padding_idx = pad_idx)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.encoder = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "  \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        # text = [batch size, sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        # packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "    \n",
    "        # Hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs = self.fc(hidden)   \n",
    "        \n",
    "        # Final activation function softmax\n",
    "        output = dense_outputs[0]\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "rwBoGE_X_Fl8"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "size_of_vocab = len(Text.vocab)\n",
    "embedding_dim = 100\n",
    "num_hidden_nodes = 256\n",
    "num_output_nodes = 5\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "PAD_IDX = Text.vocab.stoi[Text.pad_token]\n",
    "# Instantiate the model\n",
    "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-pOMqzJ3eTv",
    "outputId": "5995e95f-12c3-4979-e24f-345b323e5c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(17491, 100, padding_idx=1)\n",
      "  (encoder): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "The model has 4,060,529 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXajorf5Xz7t"
   },
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrE9RpMtZ1Vs"
   },
   "source": [
    "First define the optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "-u86JWdlXvu5"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# define optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    _, predictions = torch.max(preds, 1)\n",
    "    \n",
    "    correct = (predictions == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "    \n",
    "# push to cuda if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VCJtNb3Zt8w"
   },
   "source": [
    "The main thing to be aware of in this new training loop is that we have to reference `batch.tweets` and `batch.labels` to get the particular fields we’re interested in; they don’t fall out quite as nicely from the enumerator as they do in torchvision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WjEPLKsAiS_"
   },
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "HDWNnGK3Y5oJ"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    # initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # set the model in training phase\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        # resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        # retrieve text and no. of words\n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        # convert to 1D tensor\n",
    "        predictions = model(text, text_lengths).squeeze()  \n",
    "        \n",
    "        # compute the loss\n",
    "        loss = criterion(predictions, batch.label)        \n",
    "        \n",
    "        # compute the binary accuracy\n",
    "        acc = binary_accuracy(predictions, batch.label)   \n",
    "        \n",
    "        # backpropage the loss and compute the gradients\n",
    "        loss.backward()       \n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()      \n",
    "        \n",
    "        # loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "        epoch_acc += acc.item()    \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZcHhkkvAsCt"
   },
   "source": [
    "**Evaluation Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "zHEe-zSVAriL"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    # initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    # deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            # retrieve text and no. of words\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            # convert to 1d tensor\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "            \n",
    "            # compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            # keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6LJFW7HaJoV"
   },
   "source": [
    "**Let's Train and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tq330XlnaEU9",
    "outputId": "d5bb350a-cafb-4bf2-80b9-a7745e2b372f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.466 | Train Acc: 35.47%\n",
      "\t Val. Loss: 1.488 |  Val. Acc: 33.18% \n",
      "\n",
      "\tTrain Loss: 0.934 | Train Acc: 64.02%\n",
      "\t Val. Loss: 1.681 |  Val. Acc: 35.33% \n",
      "\n",
      "\tTrain Loss: 0.403 | Train Acc: 86.08%\n",
      "\t Val. Loss: 2.084 |  Val. Acc: 35.95% \n",
      "\n",
      "\tTrain Loss: 0.120 | Train Acc: 96.38%\n",
      "\t Val. Loss: 2.778 |  Val. Acc: 34.67% \n",
      "\n",
      "\tTrain Loss: 0.047 | Train Acc: 98.72%\n",
      "\t Val. Loss: 3.521 |  Val. Acc: 34.72% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    # train the model\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    # evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiqHNEOP38pc"
   },
   "source": [
    "### 4.  Outcomes for 25 inputs \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure we look the ouputs produced by our model makes sense, so that we can make sure the model is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spEwudVf37Dq",
    "outputId": "edb32655-6c19-4d4f-fbb3-d2cace300805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tokens\n",
      "['Effective', 'but', 'too', '-', 'tepid', 'biopic']\n",
      "\n",
      "Predicted Rating:  2        Actual Rating:  2\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "2\n",
      "tokens\n",
      "['<unk>', 'if', 'overly', 'talky', 'documentary', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  2\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "3\n",
      "tokens\n",
      "['Light', ',', 'cute', 'and', 'forgettable', '.']\n",
      "\n",
      "Predicted Rating:  2        Actual Rating:  2\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "4\n",
      "tokens\n",
      "['Between', 'the', 'drama', 'of', 'Cube', '?']\n",
      "\n",
      "Predicted Rating:  2        Actual Rating:  2\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "5\n",
      "tokens\n",
      "['It', 'is', 'nature', 'against', 'progress', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  2\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "6\n",
      "tokens\n",
      "['A', 'fascinating', 'and', 'fun', 'film', '.']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  3\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "7\n",
      "tokens\n",
      "['...', 'always', 'remains', '<unk>', 'genuine', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  3\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "8\n",
      "tokens\n",
      "['Go', 'see', 'it', 'and', 'enjoy', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  3\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "9\n",
      "tokens\n",
      "['Kinnear', 'gives', 'a', 'tremendous', 'performance', '.']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  3\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "10\n",
      "tokens\n",
      "['Hilarious', ',', 'acidic', 'Brit', 'comedy', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  3\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "11\n",
      "tokens\n",
      "['This', 'is', 'pretty', 'dicey', 'material', '.']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  1\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "12\n",
      "tokens\n",
      "['Sometimes', ',', 'that', \"'s\", 'enough', '.']\n",
      "\n",
      "Predicted Rating:  2        Actual Rating:  2\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "13\n",
      "tokens\n",
      "['Good', \"ol'\", 'urban', 'legend', 'stuff', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  0\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "14\n",
      "tokens\n",
      "['Worth', 'the', 'effort', 'to', 'watch', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  0\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "15\n",
      "tokens\n",
      "['<unk>', ',', 'provocative', 'and', 'entertaining', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  3\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "16\n",
      "tokens\n",
      "['Is', 'it', 'a', 'total', 'success', '?']\n",
      "\n",
      "Predicted Rating:  1        Actual Rating:  2\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "17\n",
      "tokens\n",
      "['A', 'wildly', 'funny', 'prison', 'caper', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  3\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "18\n",
      "tokens\n",
      "['a', 'compelling', 'portrait', 'of', 'moral', 'emptiness']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  0\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "19\n",
      "tokens\n",
      "['Invincible', 'is', 'a', 'wonderful', 'movie', '.']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  3\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "20\n",
      "tokens\n",
      "['A', 'potent', '<unk>', 'love', 'story', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  0\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "21\n",
      "tokens\n",
      "['It', \"'s\", 'like', 'a', 'poem', '.']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  0\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "22\n",
      "tokens\n",
      "['<unk>', 'in', 'its', '<unk>', 'form', '.']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  0\n",
      "Correct predcition\n",
      "---------------------------------------\n",
      "23\n",
      "tokens\n",
      "['What', 'happens', 'to', 'John', 'Q', '?']\n",
      "\n",
      "Predicted Rating:  0        Actual Rating:  2\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "24\n",
      "tokens\n",
      "['So', 'what', 'is', 'the', 'point', '?']\n",
      "\n",
      "Predicted Rating:  2        Actual Rating:  4\n",
      "Wrong Classification\n",
      "---------------------------------------\n",
      "25\n",
      "tokens\n",
      "['Lame', ',', 'haphazard', 'teen', 'comedy', '.']\n",
      "\n",
      "Predicted Rating:  1        Actual Rating:  4\n",
      "Wrong Classification\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num = 0\n",
    "for batch in valid_iterator:\n",
    "\n",
    "  if num>=25:\n",
    "    break\n",
    "  else:\n",
    "    text, text_lengths = batch.text\n",
    "    \n",
    "    predictions = model(text, text_lengths).squeeze()\n",
    "    preds = F.softmax(predictions,dim=-1)\n",
    "    if text_lengths.item()>5:\n",
    "      print(num+1)\n",
    "      print(\"tokens\")\n",
    "      print([Text.vocab.itos[x] for x in text.tolist()[0]])\n",
    "      print()\n",
    "      print(\"Predicted Rating: \",torch.argmax(preds).item(),\"      \",\"Actual Rating: \",batch.label.item())\n",
    "      print(\"Correct predcition\" if torch.argmax(preds)==batch.label.squeeze() else \"Wrong Classification\")\n",
    "      print('---------------------------------------')\n",
    "      num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KbHE8TIGRgD"
   },
   "source": [
    "### 5. 10 False Positives\n",
    "\n",
    "These are specifically texts where the model predicts the reviews to have higher scores like 3 or 4 but the actual label is 0,1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4dSD_9Q-ZoI",
    "outputId": "f11b19c4-3998-4cc5-be8e-08ddda05eb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tokens\n",
      "['This', 'is', 'pretty', 'dicey', 'material', '.']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  1\n",
      "---------------------------------------\n",
      "2\n",
      "tokens\n",
      "['It', \"'s\", 'like', 'a', 'poem', '.']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  0\n",
      "---------------------------------------\n",
      "3\n",
      "tokens\n",
      "['D.J.', '<unk>', 'as', '<unk>', 'Jones', '?']\n",
      "\n",
      "Predicted Rating:  4        Actual Rating:  2\n",
      "---------------------------------------\n",
      "4\n",
      "tokens\n",
      "['An', 'awkward', 'and', '<unk>', 'movie', '.']\n",
      "\n",
      "Predicted Rating:  4        Actual Rating:  1\n",
      "---------------------------------------\n",
      "5\n",
      "tokens\n",
      "['The', 'central', 'story', 'lacks', 'punch', '.']\n",
      "\n",
      "Predicted Rating:  4        Actual Rating:  1\n",
      "---------------------------------------\n",
      "6\n",
      "tokens\n",
      "['...', 'too', 'dull', 'to', 'enjoy', '.']\n",
      "\n",
      "Predicted Rating:  4        Actual Rating:  1\n",
      "---------------------------------------\n",
      "7\n",
      "tokens\n",
      "['Showtime', 'is', 'closer', 'to', '<unk>', '.']\n",
      "\n",
      "Predicted Rating:  4        Actual Rating:  1\n",
      "---------------------------------------\n",
      "8\n",
      "tokens\n",
      "['You', 'might', 'not', 'buy', 'the', 'ideas', '.']\n",
      "\n",
      "Predicted Rating:  4        Actual Rating:  1\n",
      "---------------------------------------\n",
      "9\n",
      "tokens\n",
      "['Here', ',', 'thankfully', ',', 'they', 'are', '.']\n",
      "\n",
      "Predicted Rating:  4        Actual Rating:  2\n",
      "---------------------------------------\n",
      "10\n",
      "tokens\n",
      "['Girls', 'gone', 'wild', 'and', 'gone', 'civil', 'again']\n",
      "\n",
      "Predicted Rating:  3        Actual Rating:  2\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num = 0\n",
    "for batch in valid_iterator:\n",
    "\n",
    "  if num>=10:\n",
    "    break\n",
    "  else:\n",
    "    text, text_lengths = batch.text\n",
    "    \n",
    "    predictions = model(text, text_lengths).squeeze()\n",
    "    preds = F.softmax(predictions,dim=-1)\n",
    "    if text_lengths.item()>5 and (torch.argmax(preds)!=batch.label.squeeze()) and (batch.label.squeeze() <= 2) and (torch.argmax(preds).item()>2):\n",
    "      print(num+1)\n",
    "      print(\"tokens\")\n",
    "      print([Text.vocab.itos[x] for x in text.tolist()[0]])\n",
    "      print()\n",
    "      print(\"Predicted Rating: \",torch.argmax(preds).item(),\"      \",\"Actual Rating: \",batch.label.item())\n",
    "      print('---------------------------------------')\n",
    "      num+=1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Standford.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
